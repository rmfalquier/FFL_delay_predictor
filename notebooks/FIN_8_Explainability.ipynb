{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gu8NAbw6Ru6b"
   },
   "source": [
    "# **Explainability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zuq9xdxIWusb"
   },
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5876,
     "status": "ok",
     "timestamp": 1738658466638,
     "user": {
      "displayName": "Rene Falquier",
      "userId": "18257220957730327135"
     },
     "user_tz": -60
    },
    "id": "YRD0nCFuXBFO"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer, RobustScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738658466639,
     "user": {
      "displayName": "Rene Falquier",
      "userId": "18257220957730327135"
     },
     "user_tz": -60
    },
    "id": "PCIztwSqXN1-"
   },
   "outputs": [],
   "source": [
    "# Load the saved model pipeline\n",
    "pipeline_rf_rus = joblib.load('pipeline_rf_rus_model.pkl')\n",
    "\n",
    "# Access the model from the pipeline\n",
    "rf_trained = pipeline_rf_rus.named_steps[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load your train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generic file path as an argument or variable\n",
    "file_path = 'yourcsv.csv'\n",
    "\n",
    "# Read the CSV file with the train data into a DataFrame\n",
    "X_train = pd.read_csv(file_path)\n",
    "\n",
    "# Define a generic file path as an argument or variable\n",
    "file_path = 'yourcsv.csv'\n",
    "\n",
    "# Read the CSV file with your test data into a DataFrame\n",
    "X_test = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding Categorical Features in Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns in X_train by selecting non-numeric columns\n",
    "# The `select_dtypes(exclude=['number'])` method selects all columns that are not numeric (i.e., categorical columns)\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "# handle_unknown=\"ignore\" ensures that categories in the test set which were not seen during training are ignored\n",
    "# sparse_output=False returns the encoded data as a dense array (DataFrame)\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "# Fit and transform the categorical columns in X_train, converting them to a one-hot encoded format\n",
    "# `encoder.fit_transform(X_train)` fits the encoder to the training data and transforms it into a one-hot encoded format\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train))\n",
    "\n",
    "# Set the column names of the transformed X_train_encoded DataFrame based on the one-hot encoded feature names\n",
    "# `get_feature_names_out()` returns the feature names generated by the encoder\n",
    "X_train_encoded.columns = encoder.get_feature_names_out()\n",
    "\n",
    "# Transform the X_test set using the same encoder (without fitting it again)\n",
    "# `encoder.transform(X_test)` transforms the test data into a one-hot encoded format using the already fitted encoder\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test))\n",
    "\n",
    "# Set the column names of the transformed X_test_encoded DataFrame to match the encoded feature names\n",
    "X_test_encoded.columns = encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining Model Predictions with SHAP for a Sample of the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738658470098,
     "user": {
      "displayName": "Rene Falquier",
      "userId": "18257220957730327135"
     },
     "user_tz": -60
    },
    "id": "5-JtzmS2A3a1"
   },
   "outputs": [],
   "source": [
    "# Initialize a SHAP explainer for the trained RandomForest model (rf_trained)\n",
    "# This will allow us to calculate Shapley values for understanding the model's predictions\n",
    "explainer = shap.TreeExplainer(rf_trained)\n",
    "\n",
    "# Sample a small subset (0.075%) of the training data for SHAP value computation\n",
    "# We use the `sample` method to randomly select a subset of rows from the encoded training data (X_train_encoded)\n",
    "# `random_state=42` ensures reproducibility of the random sample\n",
    "X_sample = X_train_encoded.sample(n=int(0.00075 * len(X_train)), random_state=42)\n",
    "\n",
    "# Reinitialize the explainer for calculating Shapley values for the sampled data\n",
    "# `check_additivity=False` disables a check for additivity of SHAP values, improving performance\n",
    "shap_values = explainer(X_sample, check_additivity=False)\n",
    "\n",
    "# Plot a summary of SHAP values for the positive class (index 1)\n",
    "# The summary plot shows the contribution of each feature to the model's output, across all samples\n",
    "# `shap_values.values[:, :, 1]` extracts the SHAP values for the positive class (class 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values.values[:, :, 1], X_sample)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
